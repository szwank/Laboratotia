% Solve an Autoregression Problem with External Input with a NARX Neural Network
% Script generated by Neural Time Series app
% Created 14-Nov-2018 10:06:20
%
% This script assumes these variables are defined:
%
%   X - input time series.
%   T - feedback time series.

% Generacja_danych_do_nauki_residula;
% X = tonndata(X,true,false);
% T = tonndata(T,true,false);

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainbr';

% trainFcn = 'traingdx';  % Gradient descent w/momentum & adaptive lr backpropagation.
% trainFcn = 'trainscg';  % Levenberg-Marquardt backpropagation.

% Create a Nonlinear Autoregressive Network with External Input
inputDelays = 0:3;
feedbackDelays = 1:3;
hiddenLayerSize = 10;

net = feedforwardnet([7,7,7],trainFcn);

% Choose Input and Feedback Pre/Post-Processing Functions
% Settings for feedback input are automatically applied to feedback output
% For a list of all processing functions type: help nnprocess
% Customize input parameters at: net.inputs{i}.processParam
% Customize output parameters at: net.outputs{i}.processParam
net.inputs{1}.processFcns = {'removeconstantrows','mapminmax'};
% net.inputs{2}.processFcns = {'removeconstantrows','mapminmax'};
% net.outputs{2}.processFcns = {'removeconstantrows','mapminmax'};

% Prepare the Data for Training and Simulation
% The function PREPARETS prepares timeseries data for a particular network,
% shifting time by the minimum amount to fill input states and layer
% states. Using PREPARETS allows you to keep your original time series data
% unchanged, while easily customizing it for networks with differing
% numbers of delays, with open loop or closed loop feedback modes.

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
 net.divideFcn = 'divideblock';  
 net.divideMode = 'time';  % Divide up every sample
 net.divideParam.trainRatio = ilosc_twarzy_treningowych_na_osobe/150;
 net.divideParam.valRatio = ilosc_twarzy_walidacyjnych_na_osobe/150;
 net.divideParam.testRatio = ilosc_twarzy_testowych_na_osobe/150;
 
% Moje ustawienia
 net.trainParam.max_fail = 100;      % Maximum validation failures
 net.trainParam.lr = 0.0001;         % Learning rate
 net.trainParam.epochs = 10^20;
 net.trainParam.min_grad = 1e-20;

 
% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'crossentropy';  % Mean Squared Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate', 'ploterrhist', ...
    'plotregression', 'plotresponse', 'ploterrcorr', 'plotinerrcorr'};
net.sampleTime=0.1;     
net = train(net,X,T);

% netg = closeloop(netg)

% net = adapt(net,x,t,xi,ai);
% netg = configure(net,X,T);
% net = adapt(net,x,t,xi,ai);
% yg = net2(xg);               % Execute on GPU
% y = gpu2nndata(yg);          % Transfer array to local workspace

% Train the Network
% [net,tr] = train(net,X,T,'useGPU','yes');

% Test the Network
y = net(X);
e = gsubtract(T,y);
performance = perform(net,T,y)

% Recalculate Training, Validation and Test Performance
% trainTargets = gmultiply(t,tr.trainMask);
% valTargets = gmultiply(t,tr.valMask);
% testTargets = gmultiply(t,tr.testMask);
% trainPerformance = perform(net,trainTargets,y)
% valPerformance = perform(net,valTargets,y)
% testPerformance = perform(net,testTargets,y)

% View the Network


% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotregression(t,y)
%figure, plotresponse(t,y)
%figure, ploterrcorr(e)
%figure, plotinerrcorr(x,e)

% Closed Loop Network
% Use this network to do multi-step prediction.
% The function CLOSELOOP replaces the feedback input with a direct
% connection from the outout layer.

    
[wynik_zdjecia_siec, ktore_zdjecie_siec] = max(cell2mat(y));
skutecznosc_siec = 0;
for i = 1:length(y)
    
   if T{i}(ktore_zdjecie_siec(i)) == 1
       skutecznosc_siec = skutecznosc_siec + 1;
   end
end

skutecznosc_siec = skutecznosc_siec / length(y)
% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x,xi,ai);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
    x1 = cell2mat(x(1,:));
    x2 = cell2mat(x(2,:));
    xi1 = cell2mat(xi(1,:));
    xi2 = cell2mat(xi(2,:));
    y = myNeuralNetworkFunction(x1,x2,xi1,xi2);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(netc,0.5);
    setsiminit(Model_slnika,silnik,netc,xi,ai,0.1)
end
